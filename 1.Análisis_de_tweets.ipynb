{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42558632-2989-42c9-8192-b4e9d2e7e49b",
   "metadata": {},
   "source": [
    "# **Caso práctico 1: Análisis de tweets**\n",
    "\n",
    "Análisis de tweets de este dataset https://github.com/garnachod/TwitterSentimentDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef4600a-b817-452c-b9af-c3080be0dd82",
   "metadata": {},
   "source": [
    "## 1. Cargar y explorar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dfedfb-e215-489e-a85f-f30c2c96324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"datos/tweets_en_es.csv\")\n",
    "dataset = dataset.sample(frac=1.0) ; dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802ecaab-ea73-415a-8f69-2439c2943302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rubrix as rb\n",
    "\n",
    "records = [\n",
    "    rb.TextClassificationRecord(\n",
    "        inputs=row.text,\n",
    "        metadata={\"source\": row.source}\n",
    "    )\n",
    "    for i,row in dataset[0:5000].iterrows()\n",
    "]\n",
    "\n",
    "rb.delete(name=\"tuits_en_es\")\n",
    "\n",
    "output = rb.log(records, name=\"tuits_en_es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaf9292-18ff-406c-b2fe-a85181e0a1cc",
   "metadata": {},
   "source": [
    "## 2. Análisis de sentimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf81098-a00b-48a7-80d7-26e67b5d1d57",
   "metadata": {},
   "source": [
    "Usaremos `pysentimiento` (https://github.com/pysentimiento/pysentimiento). Entrenado originalmente con datasets de Tweets. \n",
    "\n",
    "Creado por **Juan Manuel Pérez** (https://twitter.com/perezjotaeme)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6771347a-bff8-4da9-9595-fbfcfe943bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysentimiento import SentimentAnalyzer\n",
    "from pysentimiento.preprocessing import preprocess_tweet\n",
    "\n",
    "analyzer = SentimentAnalyzer(lang=\"es\")\n",
    "analyzer.predict(dataset.iloc[1].text).probas.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19b5b9d-7fa4-42ad-b2de-77e8015417be",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [\n",
    "    rb.TextClassificationRecord(\n",
    "        inputs=preprocess_tweet(row.text),\n",
    "        metadata={\"source\": row.source},\n",
    "        prediction=[\n",
    "            pred \n",
    "            for pred in analyzer.predict(preprocess_tweet(row.text)).probas.items()\n",
    "        ]\n",
    "    )\n",
    "    for i,row in dataset[0:100].iterrows()\n",
    "]\n",
    "rb.delete(name=\"tuits_en_es\")\n",
    "_ = rb.log(records, name=\"tuits_en_es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463a1bb3-56f9-4041-93c6-4f79137bb498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rubrix.metrics.text_classification import f1\n",
    "\n",
    "f1(name=\"tuits_en_es\") #  query=\"metadata.source:tweets_pos_clean.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53112bb4-c52c-4c7f-b800-6be6c77ca772",
   "metadata": {},
   "source": [
    "## 3. Análisis de emociones\n",
    "\n",
    "Creado por **Juan Manuel Pérez** (https://twitter.com/perezjotaeme).\n",
    "\n",
    "Ahora usaremos Hugging Face directamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfcd4d2-5305-48cd-abac-fda50acb99a8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from datasets import Dataset\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"finiteautomata/beto-emotion-analysis\", \n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "dataset = Dataset.from_csv(\"datos/tweets_en_es.csv\")\n",
    "dataset = dataset.select(range(0,100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc0afa8-9888-41ff-ad6d-8bbb9e7c86fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb.delete(\"tweets_en_es_emocion\")\n",
    "classifier = rb.monitor(classifier, dataset=\"tweets_en_es_emocion\", sample_rate=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b36319-df85-4dc2-b428-b8be638e0587",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset.map(\n",
    "    lambda r: {\"prediction\": classifier(r[\"text\"])},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd5eb31-b26d-4ddc-a08b-8c0e88b7b026",
   "metadata": {},
   "source": [
    "## 4. Categorización de texto (modelo \"zero-shot\")\n",
    "\n",
    "\n",
    "Ver tutorial: https://rubrix.readthedocs.io/en/stable/tutorials/zeroshot_data_annotation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31443668-6ab2-4d70-9496-316423818b41",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\", \n",
    "                       model=\"Recognai/zeroshot_selectra_medium\")\n",
    "\n",
    "labels = [\"amistad\", \"política\", \"videojuegos\", \"deporte\", \"comida\", \"famosos\", \"música\"]\n",
    "template = \"Este mensaje es sobre {}\"\n",
    "\n",
    "classifier = rb.monitor(classifier, dataset=\"tweets_en_es_categorizacion\", sample_rate=1.0)\n",
    "\n",
    "rb.delete(\"tweets_en_es_categorizacion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97fc2d06-335c-4a2e-96f1-54cd62f95bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'Te quiero amiga!',\n",
       " 'labels': ['amistad',\n",
       "  'famosos',\n",
       "  'música',\n",
       "  'política',\n",
       "  'deporte',\n",
       "  'comida',\n",
       "  'videojuegos'],\n",
       " 'scores': [0.9217610955238342,\n",
       "  0.02147088013589382,\n",
       "  0.016207056120038033,\n",
       "  0.014193572103977203,\n",
       "  0.010944677516818047,\n",
       "  0.008591394871473312,\n",
       "  0.0068312352523207664]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"Te quiero amiga!\", candidate_labels=labels, hypothesis_template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e23d40c-d78f-4db0-93f9-f9e10efb7660",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f319275f9145d7b21fe22a0d7f7bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'text', 'source', 'prediction'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.map(\n",
    "    lambda r: {\"prediction\": classifier(r[\"text\"], candidate_labels=labels, hypothesis_template=template)}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e655b3-0cdd-4ca8-bd2c-e744ebe904b1",
   "metadata": {},
   "source": [
    "## 5. Reconocimiento de entidades con spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10b2bcd-8928-4775-af06-6dfdcaa8dd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4efd7a2f-75be-416c-816e-9273ed8f643b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-a85a1ff4f4fab58b\n",
      "Reusing dataset csv (/Users/dani/.cache/huggingface/datasets/csv/default-a85a1ff4f4fab58b/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import rubrix as rb\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "nlp = rb.monitor(nlp, dataset=\"tuits_ner\")\n",
    "\n",
    "rb.delete(\"tuits_ner\")\n",
    "\n",
    "dataset = Dataset.from_csv(\"tweets_en_es.csv\")\n",
    "dataset = dataset.select(range(0,1000)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cca682bc-efa4-42e8-a391-0790cbde88b8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2951d8f6deb240deb29d41dbc011d10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'text', 'source', 'processed'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_record(r):\n",
    "    doc = nlp(record[\"text\"])\n",
    "    return {\"processed\": True}\n",
    "\n",
    "dataset.map(process_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c9667b-b19b-43bc-9095-1d647173d95e",
   "metadata": {},
   "source": [
    "## 6. ¿Cómo entrenar un modelo una vez etiquetados los datos?\n",
    "\n",
    "Ver tutorial completo en: https://rubrix.readthedocs.io/en/stable/tutorials/01-labeling-finetuning.html\n",
    "\n",
    "![Labeling workflow](https://rubrix.readthedocs.io/en/stable/_images/workflow.svg \"Labeling workflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58504dfd-1b2d-49b6-8c84-72bc0e116241",
   "metadata": {},
   "source": [
    "### Preparación de datos entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db7faa77-a0f0-4a2d-ab83-c0230ebfc33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_df = rb.load(\n",
    "    name='tweets_en_es_emocion', \n",
    "    query=\"status:Validated\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20998b22-8fcc-4fc4-afbd-60b4b8bbd41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dbdea5-a457-4861-840e-0a2709770ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# select text input and the annotated label\n",
    "rb_df['text'] = rb_df.inputs.transform(lambda r: r['text'])\n",
    "rb_df['labels'] = rb_df.annotation\n",
    "\n",
    "\n",
    "# create 🤗 dataset from pandas with labels as numeric ids\n",
    "label2id = { label:i for i,label in enumerate([\"joy\", \"sadness\", \"fear\", \"others\", \"surprise\", \"disgust\"])}\n",
    "train_ds = Dataset.from_pandas(rb_df[['text', 'labels']])\n",
    "train_ds = train_ds.map(lambda example: {'labels': label2id[example['labels']]})\n",
    "\n",
    "train_ds = train_ds.train_test_split(test_size=0.2) ; train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0237abf9-7430-418a-b54e-e06ee9991973",
   "metadata": {},
   "source": [
    "A partir de este punto se puede seguir el proceso estándar con el Hugging Face `Trainer` (ver tutorial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
