{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42558632-2989-42c9-8192-b4e9d2e7e49b",
   "metadata": {},
   "source": [
    "# **Caso práctico 1: Análisis de tweets**\n",
    "\n",
    "Análisis de tweets de este dataset https://github.com/garnachod/TwitterSentimentDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef4600a-b817-452c-b9af-c3080be0dd82",
   "metadata": {},
   "source": [
    "## 1. Cargar y explorar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46dfedfb-e215-489e-a85f-f30c2c96324a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99233</th>\n",
       "      <td>43873</td>\n",
       "      <td>1509. Hace UN SIGLO que no hablamos :(\\n</td>\n",
       "      <td>tweets_neg_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89888</th>\n",
       "      <td>34528</td>\n",
       "      <td>Suelen ser los que más ensucian :( https://t.c...</td>\n",
       "      <td>tweets_neg_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194909</th>\n",
       "      <td>17333</td>\n",
       "      <td>Cuando Consuelo Císcar se creyó Marco Polo htt...</td>\n",
       "      <td>tweets_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130703</th>\n",
       "      <td>75343</td>\n",
       "      <td>La única que me manda snaps es Kiara y no son ...</td>\n",
       "      <td>tweets_neg_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143792</th>\n",
       "      <td>88432</td>\n",
       "      <td>@Reynerosrvng Ah! .... q triste :(\\n</td>\n",
       "      <td>tweets_neg_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19572</th>\n",
       "      <td>19572</td>\n",
       "      <td>@camilacabello97 mijaaa llegaste a los 2 millo...</td>\n",
       "      <td>tweets_pos_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47372</th>\n",
       "      <td>47372</td>\n",
       "      <td>al final todo va a estar bien :) http://t.co/K...</td>\n",
       "      <td>tweets_pos_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211488</th>\n",
       "      <td>33912</td>\n",
       "      <td>@MMiguelj30 No la conozco. La apunto a la list...</td>\n",
       "      <td>tweets_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130776</th>\n",
       "      <td>75416</td>\n",
       "      <td>EXTRAÑO A MIS AMIGAS :( @PauManavella00 @taaru...</td>\n",
       "      <td>tweets_neg_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39925</th>\n",
       "      <td>39925</td>\n",
       "      <td>@mariagv \"Deseandico\" me ha encantado.  Un #ol...</td>\n",
       "      <td>tweets_pos_clean.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248310 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  ...                source\n",
       "99233        43873  ...  tweets_neg_clean.txt\n",
       "89888        34528  ...  tweets_neg_clean.txt\n",
       "194909       17333  ...      tweets_clean.txt\n",
       "130703       75343  ...  tweets_neg_clean.txt\n",
       "143792       88432  ...  tweets_neg_clean.txt\n",
       "...            ...  ...                   ...\n",
       "19572        19572  ...  tweets_pos_clean.txt\n",
       "47372        47372  ...  tweets_pos_clean.txt\n",
       "211488       33912  ...      tweets_clean.txt\n",
       "130776       75416  ...  tweets_neg_clean.txt\n",
       "39925        39925  ...  tweets_pos_clean.txt\n",
       "\n",
       "[248310 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"datos/tweets_en_es.csv\")\n",
    "dataset = dataset.sample(frac=1.0) ; dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "802ecaab-ea73-415a-8f69-2439c2943302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rubrix as rb\n",
    "\n",
    "records = [\n",
    "    rb.TextClassificationRecord(\n",
    "        inputs=row.text,\n",
    "        metadata={\"source\": row.source}\n",
    "    )\n",
    "    for i,row in dataset[0:5000].iterrows()\n",
    "]\n",
    "\n",
    "rb.delete(name=\"tuits_en_es\")\n",
    "\n",
    "output = rb.log(records, name=\"tuits_en_es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c19c7e0-550f-42b1-b3a0-b97c24d5751f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>prediction</th>\n",
       "      <th>annotation</th>\n",
       "      <th>prediction_agent</th>\n",
       "      <th>annotation_agent</th>\n",
       "      <th>multi_label</th>\n",
       "      <th>explanation</th>\n",
       "      <th>id</th>\n",
       "      <th>metadata</th>\n",
       "      <th>status</th>\n",
       "      <th>event_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'text': 'Personas lindas con camisas lindas :...</td>\n",
       "      <td>None</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>None</td>\n",
       "      <td>rubrix</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0002390b-cc0c-4c14-8f7c-1b3b61fa45dc</td>\n",
       "      <td>{'source': 'tweets_neg_clean.txt'}</td>\n",
       "      <td>Validated</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'text': 'El Arte de Aplaudir con las nalgas :...</td>\n",
       "      <td>None</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>None</td>\n",
       "      <td>rubrix</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>000e680f-5981-4ad8-9d8b-f84f666cfa91</td>\n",
       "      <td>{'source': 'tweets_pos_clean.txt'}</td>\n",
       "      <td>Validated</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'text': 'Necesito que alguien vea Mr Robot y ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>None</td>\n",
       "      <td>rubrix</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0018a876-c4f4-4059-b93b-2521bcd264b9</td>\n",
       "      <td>{'source': 'tweets_neg_clean.txt'}</td>\n",
       "      <td>Validated</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              inputs  ... event_timestamp\n",
       "0  {'text': 'Personas lindas con camisas lindas :...  ...            None\n",
       "1  {'text': 'El Arte de Aplaudir con las nalgas :...  ...            None\n",
       "2  {'text': 'Necesito que alguien vea Mr Robot y ...  ...            None\n",
       "\n",
       "[3 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb.load(\"tuits_en_es\", query=\"status:Validated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaf9292-18ff-406c-b2fe-a85181e0a1cc",
   "metadata": {},
   "source": [
    "## 2. Análisis de sentimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf81098-a00b-48a7-80d7-26e67b5d1d57",
   "metadata": {},
   "source": [
    "Usaremos `pysentimiento` (https://github.com/pysentimiento/pysentimiento). Entrenado originalmente con datasets de Tweets. \n",
    "\n",
    "Creado por **Juan Manuel Pérez** (https://twitter.com/perezjotaeme)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6771347a-bff8-4da9-9595-fbfcfe943bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('NEG', 0.9988141059875488), ('NEU', 0.0006684837280772626), ('POS', 0.0005174684920348227)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pysentimiento import SentimentAnalyzer\n",
    "from pysentimiento.preprocessing import preprocess_tweet\n",
    "\n",
    "analyzer = SentimentAnalyzer(lang=\"es\")\n",
    "analyzer.predict(dataset.iloc[1].text).probas.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bd90802-7304-4b4b-aa01-959126a0fe48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentOutput(output=POS, probas={POS: 0.999, NEG: 0.001, NEU: 0.001})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = analyzer.predict(\"Hola me llamo Daniel y estoy contento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f19b5b9d-7fa4-42ad-b2de-77e8015417be",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [\n",
    "    rb.TextClassificationRecord(\n",
    "        inputs=preprocess_tweet(row.text),\n",
    "        metadata={\"source\": row.source},\n",
    "        #annotation=analyzer.predict(preprocess_tweet(row.text)).probas.items()[0] This will load the annotation as a valid label\n",
    "        prediction=[prediction for prediction in analyzer.predict(preprocess_tweet(row.text)).probas.items()]\n",
    "    )\n",
    "    for i,row in dataset[0:100].iterrows()\n",
    "]\n",
    "rb.delete(name=\"tuits_en_es\")\n",
    "_ = rb.log(records, name=\"tuits_en_es_nuevo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "463a1bb3-56f9-4041-93c6-4f79137bb498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetricSummary(data={'micro': 0.8888888888888888, 'macro': 0.6363636363636364, 'per_label': {'POS': 1.0, 'NEU': 0.0, 'NEG': 0.9090909090909091}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rubrix.metrics.text_classification import f1\n",
    "\n",
    "f1(name=\"tuits_en_es\") #  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53112bb4-c52c-4c7f-b800-6be6c77ca772",
   "metadata": {},
   "source": [
    "## 3. Análisis de emociones\n",
    "\n",
    "Creado por **Juan Manuel Pérez** (https://twitter.com/perezjotaeme).\n",
    "\n",
    "Ahora usaremos Hugging Face directamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4dfcd4d2-5305-48cd-abac-fda50acb99a8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/finiteautomata/beto-emotion-analysis/resolve/main/config.json from cache at /Users/dani/.cache/huggingface/transformers/b75b62ad64772a1df4c46943b8729e726a8bcc147e845197d591ebde2d1430b2.516dbdb8064a2498055e9af6e5d92ae5a4583bcefe0ca71535c71f42cf513138\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"others\",\n",
      "    \"1\": \"joy\",\n",
      "    \"2\": \"sadness\",\n",
      "    \"3\": \"anger\",\n",
      "    \"4\": \"surprise\",\n",
      "    \"5\": \"disgust\",\n",
      "    \"6\": \"fear\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 3,\n",
      "    \"disgust\": 5,\n",
      "    \"fear\": 6,\n",
      "    \"joy\": 1,\n",
      "    \"others\": 0,\n",
      "    \"sadness\": 2,\n",
      "    \"surprise\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31006\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/finiteautomata/beto-emotion-analysis/resolve/main/config.json from cache at /Users/dani/.cache/huggingface/transformers/b75b62ad64772a1df4c46943b8729e726a8bcc147e845197d591ebde2d1430b2.516dbdb8064a2498055e9af6e5d92ae5a4583bcefe0ca71535c71f42cf513138\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"others\",\n",
      "    \"1\": \"joy\",\n",
      "    \"2\": \"sadness\",\n",
      "    \"3\": \"anger\",\n",
      "    \"4\": \"surprise\",\n",
      "    \"5\": \"disgust\",\n",
      "    \"6\": \"fear\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 3,\n",
      "    \"disgust\": 5,\n",
      "    \"fear\": 6,\n",
      "    \"joy\": 1,\n",
      "    \"others\": 0,\n",
      "    \"sadness\": 2,\n",
      "    \"surprise\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31006\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/finiteautomata/beto-emotion-analysis/resolve/main/pytorch_model.bin from cache at /Users/dani/.cache/huggingface/transformers/3340fd56aeb259af2588d2310cd2b65003da73c71a0b3a9b194261e0f6f7a947.3ee7c714ba16bbcb5520130b897e21deeef4b8547c73faea6878ea623d25bc6a\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at finiteautomata/beto-emotion-analysis.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/finiteautomata/beto-emotion-analysis/resolve/main/config.json from cache at /Users/dani/.cache/huggingface/transformers/b75b62ad64772a1df4c46943b8729e726a8bcc147e845197d591ebde2d1430b2.516dbdb8064a2498055e9af6e5d92ae5a4583bcefe0ca71535c71f42cf513138\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"others\",\n",
      "    \"1\": \"joy\",\n",
      "    \"2\": \"sadness\",\n",
      "    \"3\": \"anger\",\n",
      "    \"4\": \"surprise\",\n",
      "    \"5\": \"disgust\",\n",
      "    \"6\": \"fear\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 3,\n",
      "    \"disgust\": 5,\n",
      "    \"fear\": 6,\n",
      "    \"joy\": 1,\n",
      "    \"others\": 0,\n",
      "    \"sadness\": 2,\n",
      "    \"surprise\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31006\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/finiteautomata/beto-emotion-analysis/resolve/main/vocab.txt from cache at /Users/dani/.cache/huggingface/transformers/182e659b57f089303d9beba9b54d4bbc33e388ea869b153a83344146934df088.6587bde86239957281af55b2f7e564df111a2b4f9dfc0ad884f13ea7106e4dfb\n",
      "loading file https://huggingface.co/finiteautomata/beto-emotion-analysis/resolve/main/tokenizer.json from cache at /Users/dani/.cache/huggingface/transformers/d3ec1c07c1293a1f9a278e349641eff4ee1317eadc6625e7f0d740aed9d0c3e6.7bb78e6bcd16fd5afcc81f874d642c4c0e37c5a70d9c4cae22a5ef652a474211\n",
      "loading file https://huggingface.co/finiteautomata/beto-emotion-analysis/resolve/main/added_tokens.json from cache at /Users/dani/.cache/huggingface/transformers/17175619af4cf779d700ee7d96d939b4a2e370552f3e212b28706988c07bc757.3bdabf8f0209d2860f770add80e3711ab238cbb392a68cc562df9a4f94237507\n",
      "loading file https://huggingface.co/finiteautomata/beto-emotion-analysis/resolve/main/special_tokens_map.json from cache at /Users/dani/.cache/huggingface/transformers/1b11459e7e69246d319a1fdec54171a4b3b1420078955aa63daebe50a0639ac5.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/finiteautomata/beto-emotion-analysis/resolve/main/tokenizer_config.json from cache at /Users/dani/.cache/huggingface/transformers/b515a7f7f7c5ab818cb49fe535d9886b05f726253b73e8233fba3b1eb1d9dda9.6610639a3a01ef41e1083c8f282f39d442a64ca8691291be4444213bf598269d\n",
      "loading configuration file https://huggingface.co/finiteautomata/beto-emotion-analysis/resolve/main/config.json from cache at /Users/dani/.cache/huggingface/transformers/b75b62ad64772a1df4c46943b8729e726a8bcc147e845197d591ebde2d1430b2.516dbdb8064a2498055e9af6e5d92ae5a4583bcefe0ca71535c71f42cf513138\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"dccuchile/bert-base-spanish-wwm-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"others\",\n",
      "    \"1\": \"joy\",\n",
      "    \"2\": \"sadness\",\n",
      "    \"3\": \"anger\",\n",
      "    \"4\": \"surprise\",\n",
      "    \"5\": \"disgust\",\n",
      "    \"6\": \"fear\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"anger\": 3,\n",
      "    \"disgust\": 5,\n",
      "    \"fear\": 6,\n",
      "    \"joy\": 1,\n",
      "    \"others\": 0,\n",
      "    \"sadness\": 2,\n",
      "    \"surprise\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31006\n",
      "}\n",
      "\n",
      "Using custom data configuration default-a85a1ff4f4fab58b\n",
      "Reusing dataset csv (/Users/dani/.cache/huggingface/datasets/csv/default-a85a1ff4f4fab58b/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from datasets import Dataset\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"finiteautomata/beto-emotion-analysis\", \n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "dataset = Dataset.from_csv(\"datos/tweets_en_es.csv\")\n",
    "dataset = dataset.select(range(0,100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc0afa8-9888-41ff-ad6d-8bbb9e7c86fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb.delete(\"tweets_en_es_emocion\")\n",
    "\n",
    "classifier = rb.monitor(classifier, dataset=\"tweets_en_es_emocion\", sample_rate=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b36319-df85-4dc2-b428-b8be638e0587",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset.map(\n",
    "    lambda r: {\"prediction\": classifier(r[\"text\"])},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd5eb31-b26d-4ddc-a08b-8c0e88b7b026",
   "metadata": {},
   "source": [
    "## 4. Categorización de texto (modelo \"zero-shot\")\n",
    "\n",
    "\n",
    "Ver tutorial: https://rubrix.readthedocs.io/en/stable/tutorials/zeroshot_data_annotation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31443668-6ab2-4d70-9496-316423818b41",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\", \n",
    "                       model=\"Recognai/zeroshot_selectra_medium\")\n",
    "\n",
    "labels = [\"amistad\", \"política\", \"videojuegos\", \"deporte\", \"comida\", \"famosos\", \"música\"]\n",
    "template = \"Este mensaje es sobre {}\"\n",
    "\n",
    "classifier = rb.monitor(classifier, dataset=\"tweets_en_es_categorizacion\", sample_rate=1.0)\n",
    "\n",
    "rb.delete(\"tweets_en_es_categorizacion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97fc2d06-335c-4a2e-96f1-54cd62f95bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'Te quiero amiga!',\n",
       " 'labels': ['amistad',\n",
       "  'famosos',\n",
       "  'música',\n",
       "  'política',\n",
       "  'deporte',\n",
       "  'comida',\n",
       "  'videojuegos'],\n",
       " 'scores': [0.9217610955238342,\n",
       "  0.02147088013589382,\n",
       "  0.016207056120038033,\n",
       "  0.014193572103977203,\n",
       "  0.010944677516818047,\n",
       "  0.008591394871473312,\n",
       "  0.0068312352523207664]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"Te quiero amiga!\", candidate_labels=labels, hypothesis_template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e23d40c-d78f-4db0-93f9-f9e10efb7660",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f319275f9145d7b21fe22a0d7f7bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'text', 'source', 'prediction'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.map(\n",
    "    lambda r: {\"prediction\": classifier(r[\"text\"], candidate_labels=labels, hypothesis_template=template)}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e655b3-0cdd-4ca8-bd2c-e744ebe904b1",
   "metadata": {},
   "source": [
    "## 5. Reconocimiento de entidades con spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10b2bcd-8928-4775-af06-6dfdcaa8dd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4efd7a2f-75be-416c-816e-9273ed8f643b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-a85a1ff4f4fab58b\n",
      "Reusing dataset csv (/Users/dani/.cache/huggingface/datasets/csv/default-a85a1ff4f4fab58b/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import rubrix as rb\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "nlp = rb.monitor(nlp, dataset=\"tuits_ner\")\n",
    "\n",
    "rb.delete(\"tuits_ner\")\n",
    "\n",
    "dataset = Dataset.from_csv(\"tweets_en_es.csv\")\n",
    "dataset = dataset.select(range(0,1000)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cca682bc-efa4-42e8-a391-0790cbde88b8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/dani/.cache/huggingface/datasets/csv/default-a85a1ff4f4fab58b/0.0.0/cache-1c80317fa3b1799d.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'text', 'source', 'prediction'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_record(r):\n",
    "    doc = nlp(r[\"text\"])\n",
    "    return {\"processed\": True}\n",
    "\n",
    "dataset.map(process_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c9667b-b19b-43bc-9095-1d647173d95e",
   "metadata": {},
   "source": [
    "## 6. ¿Cómo entrenar un modelo una vez etiquetados los datos?\n",
    "\n",
    "Ver tutorial completo en: https://rubrix.readthedocs.io/en/stable/tutorials/01-labeling-finetuning.html\n",
    "\n",
    "![Labeling workflow](https://rubrix.readthedocs.io/en/stable/_images/workflow.svg \"Labeling workflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58504dfd-1b2d-49b6-8c84-72bc0e116241",
   "metadata": {},
   "source": [
    "### Preparación de datos entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db7faa77-a0f0-4a2d-ab83-c0230ebfc33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_df = rb.load(\n",
    "    name='tweets_en_es_emocion', \n",
    "    query=\"status:Validated\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20998b22-8fcc-4fc4-afbd-60b4b8bbd41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dbdea5-a457-4861-840e-0a2709770ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# select text input and the annotated label\n",
    "rb_df['text'] = rb_df.inputs.transform(lambda r: r['text'])\n",
    "rb_df['labels'] = rb_df.annotation\n",
    "\n",
    "\n",
    "# create 🤗 dataset from pandas with labels as numeric ids\n",
    "label2id = { label:i for i,label in enumerate([\"joy\", \"sadness\", \"fear\", \"others\", \"surprise\", \"disgust\"])}\n",
    "train_ds = Dataset.from_pandas(rb_df[['text', 'labels']])\n",
    "train_ds = train_ds.map(lambda example: {'labels': label2id[example['labels']]})\n",
    "\n",
    "train_ds = train_ds.train_test_split(test_size=0.2) ; train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0237abf9-7430-418a-b54e-e06ee9991973",
   "metadata": {},
   "source": [
    "A partir de este punto se puede seguir el proceso estándar con el Hugging Face `Trainer` (ver tutorial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
