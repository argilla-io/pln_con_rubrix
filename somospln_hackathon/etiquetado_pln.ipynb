{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a65ec80-f6a1-45ad-9c7d-78807ea55b55",
   "metadata": {},
   "source": [
    "# **Etiquetado para PLN con Rubrix**\n",
    "\n",
    "## **¿Qué es Rubrix?**\n",
    "### *Una herramienta gratuita y de código abierto para construir y mejorar datos de entrenamiento para PLN.*\n",
    "\n",
    "Rubrix se compone de dos elementos:\n",
    "\n",
    "- Una **aplicación web** para explorar, anotar y revisar datos.\n",
    "- Una **librería Python** para crear datasets, pre-anotar, anotar programáticamente, mejorar datos, etc.\n",
    "\n",
    "## **Cómo te podemos ayudar**\n",
    "\n",
    "Si tienes dudas tenemos una comunidad muy activa y un equipo dedicado a Rubrix:\n",
    "\n",
    "1. Únete a nuestro Slack (ver enlace en la web https://www.rubrix.ml/)\n",
    "2. Escribe una issue en Github: https://github.com/recognai/rubrix\n",
    "\n",
    "## **Si te gusta Rubrix, ¿cómo nos puedes ayudar?**\n",
    "\n",
    "1. Agradecemos cualquier tipo de feedback, sugerencias, etc.\n",
    "2. Para dar visibilidad al proyecto, dale una estrella en Github: https://github.com/recognai/rubrix\n",
    "3. Comparte con tus contactos!\n",
    "4. Si te apetece escribir sobre NLP práctico y datos, nuestro blog está abierto para cualquier persona.\n",
    "\n",
    "\n",
    "## **Guión del taller**\n",
    "0. Cómo instalar y lanzar Rubrix\n",
    "1. Cómo subir o crear datasets para anotar para clasificación de texto\n",
    "2. Cómo pre-anotar un dataset con un modelo pre-entrenado para clasificación de texto\n",
    "3. Como etiquetar un dataset para clasificación de texto\n",
    "4. Cómo entrenar un clasificador de texto\n",
    "5. Cómo subir o crear datasets para anotar para NER\n",
    "6. Cómo etiquetar un dataset para NER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d669a6a1-5cf7-4021-ba21-6be73415286b",
   "metadata": {},
   "source": [
    "## **Cómo instalar y lanzar Rubrix**\n",
    "\n",
    "Necesitamos:\n",
    "\n",
    "1. Elasticsearch (Recomendable lanzarlo usando Docker)\n",
    "2. Python >= 3.7\n",
    "3. Instalar rubrix con `pip install rubrix[server]`\n",
    "\n",
    "Cómo lo lanzamos:\n",
    "\n",
    "1. Arrancamos Elasticsearch (con esto tenemos la base de datos y el motor de búsqueda). \n",
    "2. Lanzamos la aplicación web de Rubrix con `python -m rubrix`\n",
    "3. Recomendable usar Jupyter notebooks (JupyterLab, VS Code, etc.). Para usarlo con Colab necesitaremos tener una instancia Cloud de Rubrix (ver guía despliegue en AWS)\n",
    "\n",
    "Para este taller necesitamos además:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d8c43f-8784-4911-a55f-e880a445dafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install snorkel datasets transformers torch spacy -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68f2208-c514-4f6b-a6cd-066e7c04099c",
   "metadata": {},
   "source": [
    "## **1. Cómo subir o crear un dataset para clasificación de texto**\n",
    "\n",
    "Usando la librería python en Rubrix.\n",
    "\n",
    "\n",
    "### Usando objetos `TextClassificationRecord`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fee458e9-7099-43ea-880d-44f0b381695a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d65c9c7f504c5cae2258e110a2b4b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 records logged to http://localhost:6900/ws/rubrix/test_dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BulkResponse(dataset='test_dataset', processed=1, failed=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rubrix as rb\n",
    "from rubrix import read_datasets\n",
    "\n",
    "# usando las clases de registro de cada tarea: TextClassificationRecord, TokenClassificationRecord, etc.\n",
    "rb.log(\n",
    "    rb.TextClassificationRecord(text=\"mi primer registro\"), \n",
    "    \"test_dataset\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4173b17-0181-4daf-aa3d-47bb2514fc63",
   "metadata": {},
   "source": [
    "### Usando from_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eacacde9-7a0d-4a8a-bebe-f0728ed74bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Se imaginan a los chicos agradeciendo por el p...</td>\n",
       "      <td>tweets_pos_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Eclesiastes4:9-12 ♡ Siempre, promesa :)  https...</td>\n",
       "      <td>tweets_pos_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@pedroj_ramirez Qué saborío, PJ. ya no compart...</td>\n",
       "      <td>tweets_pos_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Buenos dias para todos. Feliz inicio de semana...</td>\n",
       "      <td>tweets_pos_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@pepedom @bquintero Gracias! No es así, deja c...</td>\n",
       "      <td>tweets_pos_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248305</th>\n",
       "      <td>70729</td>\n",
       "      <td>.@EsperanzAguirre y @mdcospedal se presentan a...</td>\n",
       "      <td>tweets_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248306</th>\n",
       "      <td>70730</td>\n",
       "      <td>Desde aquí twiteo siempre http://t.co/JcH0yKr3\\n</td>\n",
       "      <td>tweets_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248307</th>\n",
       "      <td>70731</td>\n",
       "      <td>Es un honor y una necesidad política estar a p...</td>\n",
       "      <td>tweets_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248308</th>\n",
       "      <td>70732</td>\n",
       "      <td>\"La salud y la vida de las mujeres vale más qu...</td>\n",
       "      <td>tweets_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248309</th>\n",
       "      <td>70733</td>\n",
       "      <td>Cinco estafadores que todo emprendedor se enco...</td>\n",
       "      <td>tweets_clean.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248310 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  \\\n",
       "0                0  Se imaginan a los chicos agradeciendo por el p...   \n",
       "1                1  Eclesiastes4:9-12 ♡ Siempre, promesa :)  https...   \n",
       "2                2  @pedroj_ramirez Qué saborío, PJ. ya no compart...   \n",
       "3                3  Buenos dias para todos. Feliz inicio de semana...   \n",
       "4                4  @pepedom @bquintero Gracias! No es así, deja c...   \n",
       "...            ...                                                ...   \n",
       "248305       70729  .@EsperanzAguirre y @mdcospedal se presentan a...   \n",
       "248306       70730   Desde aquí twiteo siempre http://t.co/JcH0yKr3\\n   \n",
       "248307       70731  Es un honor y una necesidad política estar a p...   \n",
       "248308       70732  \"La salud y la vida de las mujeres vale más qu...   \n",
       "248309       70733  Cinco estafadores que todo emprendedor se enco...   \n",
       "\n",
       "                      source  \n",
       "0       tweets_pos_clean.txt  \n",
       "1       tweets_pos_clean.txt  \n",
       "2       tweets_pos_clean.txt  \n",
       "3       tweets_pos_clean.txt  \n",
       "4       tweets_pos_clean.txt  \n",
       "...                      ...  \n",
       "248305      tweets_clean.txt  \n",
       "248306      tweets_clean.txt  \n",
       "248307      tweets_clean.txt  \n",
       "248308      tweets_clean.txt  \n",
       "248309      tweets_clean.txt  \n",
       "\n",
       "[248310 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# usando pandas para leer un csv, json, etc.\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/recognai/pln_con_rubrix/main/datos/tweets_en_es.csv\"); df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead6c96d-f7d4-4f80-9995-46cfe6a71069",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb.log(rb.DatasetForTextClassification().from_pandas(df[0:10]), \"pandas_ds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10e33e2-526e-4464-9e13-71b2b79ff1c6",
   "metadata": {},
   "source": [
    "### Usando from_datasets y leyendo datasets del Hub de Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8886eb-685e-4d9c-9dad-cd769a1fba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"muchocine\", split=\"train\") ; dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeeb77b-1c85-4aa4-851c-121937d946c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_dataset = rb.DatasetForTextClassification().from_datasets(\n",
    "    dataset, \n",
    "    inputs=['review_body', 'review_summary'], \n",
    "    annotation=\"star_rating\"\n",
    ")\n",
    "\n",
    "rb.log(rb_dataset, \"rb_muchocine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4b2e7c-8d0c-466f-83cc-a7511bb5fc7d",
   "metadata": {},
   "source": [
    "## **2. Cómo pre-anotar un dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a959b1-9176-4dd4-9a70-9404fe11a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "dataset = load_dataset(\"rubrix/muchocine_aspects\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8362b2bc-a2f6-46c5-a473-b48db44631d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88dbce9159b482fba28eaa8032beb60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/997 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff8a4a3e3ed49dda6257bf32c3215e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/85.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23918aba7cf4437970e7bea48cf1b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/337 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c97439d534eb4791a0c22eefa2ae14f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/378k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc4c7d7d8cc491bbae671097f584783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/760k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dbc7fa67c0d4c9ebc0af9a3151c2cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = pipeline(\n",
    "    \"zero-shot-classification\", \n",
    "    model=\"Recognai/zeroshot_selectra_small\", \n",
    "    return_all_scores=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ffab4d64-1b5d-4f7a-9203-ef8d3b40e305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'La historia es lo mejor de la película',\n",
       " 'labels': ['direccción', 'interpretacción', 'aspectos formales', 'guión'],\n",
       " 'scores': [0.7319302558898926,\n",
       "  0.18849410116672516,\n",
       "  0.051197148859500885,\n",
       "  0.028378522023558617]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"La historia es lo mejor de la película\", candidate_labels=labels, hypothesis_template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b1195f24-7d59-474d-a147-7e6b9eff55a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b773305e0ca04c7babcbd34ce9cdd9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 records logged to http://localhost:6900/ws/rubrix/news_zeroshot\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BulkResponse(dataset='news_zeroshot', processed=10, failed=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [\"guión\", \"direccción\", \"aspectos formales\", \"interpretacción\"]\n",
    "template = \"La frase es sobre {}\"\n",
    "\n",
    "records = []\n",
    "\n",
    "for record in dataset.select(range(10)):\n",
    "    prediction = nlp(record['text'], labels)\n",
    "\n",
    "    records.append(\n",
    "        rb.TextClassificationRecord(\n",
    "            text=record[\"text\"],\n",
    "            prediction=list(zip(prediction['labels'], prediction['scores'])),\n",
    "        )\n",
    "    )\n",
    "\n",
    "rb.log(records, name=\"news_zeroshot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a5cc05-12d9-47fb-9338-57bb9f20bae7",
   "metadata": {},
   "source": [
    "## **3. Cómo etiquetar un dataset para clasificación de texto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0988fd1a-446e-4dfd-80ea-340a89c38f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"rubrix/muchocine_aspects\", split=\"train\")\n",
    "\n",
    "rb.log(read_datasets(dataset, task=\"TextClassification\"),\"muchocine_aspects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0ec527-62b3-4687-bc7d-a14ad596874b",
   "metadata": {},
   "source": [
    "## **4. Cómo entrenar un clasificador de texto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7b613c0e-1f00-42ab-81dc-72efe682309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = rb.load(\"muchocine_aspect\", query=\"status:Validated\", as_pandas=False).prepare_for_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ec8f61-4778-402c-87a9-c8d9a8ad1f6a",
   "metadata": {},
   "source": [
    "### Fine-tune con transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "59a355a9-d7f7-4096-8dfc-4047d6c5565a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f19a7c3f53444a3182996abf2743dd3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "from transformers import Trainer\n",
    "from datasets import load_metric\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "model_id = \"Recognai/selectra_small\"\n",
    "\n",
    "# tokenize our datasets\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "ds = ds.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2111b8f4-bb9f-4581-85a6-95611d906daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into a training and evalutaion set\n",
    "train_dataset, eval_dataset = ds.train_test_split(test_size=0.2, seed=42).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb3a27-e308-4184-bf1c-21fc50ad2822",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {idx:label for idx,label in enumerate(ds.features[\"label\"].names)}\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=len(ds.features[\"label\"].names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f5729a51-8bce-4073-8c33-1e2675cc4399",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    \"muchocine_aspects\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_steps=30,\n",
    "    num_train_epochs=2\n",
    ")\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "trainer = Trainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2798c2b6-cea4-4ef6-98e5-7897c8b1166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846baf51-5288-41ce-9f0d-18f113dcbd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb9d737-3eac-4042-add4-a320638ac8ca",
   "metadata": {},
   "source": [
    "### **5. Usando weak supervision**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cee9577a-06e3-4551-8e35-69b3e6387aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3470c109b6ab45f88b2dbdfff2bfc0ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preparing rules:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623d84f30b824f8ebc8165aabe75736d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying rules:   0%|          | 0/69227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>coverage</th>\n",
       "      <th>annotated_coverage</th>\n",
       "      <th>overlaps</th>\n",
       "      <th>conflicts</th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>interpreta*</th>\n",
       "      <td>{interpretación}</td>\n",
       "      <td>0.028269</td>\n",
       "      <td>0.127072</td>\n",
       "      <td>0.004102</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trama</th>\n",
       "      <td>{guión}</td>\n",
       "      <td>0.012322</td>\n",
       "      <td>0.116022</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banda sonora</th>\n",
       "      <td>{aspectos formales}</td>\n",
       "      <td>0.006168</td>\n",
       "      <td>0.027624</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fotografía</th>\n",
       "      <td>{aspectos formales}</td>\n",
       "      <td>0.008754</td>\n",
       "      <td>0.033149</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reparto</th>\n",
       "      <td>{interpretación}</td>\n",
       "      <td>0.007280</td>\n",
       "      <td>0.038674</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(guion AND NOT actor*)</th>\n",
       "      <td>{guión}</td>\n",
       "      <td>0.020324</td>\n",
       "      <td>0.110497</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director*</th>\n",
       "      <td>{dirección}</td>\n",
       "      <td>0.039074</td>\n",
       "      <td>0.171271</td>\n",
       "      <td>0.004117</td>\n",
       "      <td>0.004117</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>{guión, interpretación, aspectos formales, dir...</td>\n",
       "      <td>0.112427</td>\n",
       "      <td>0.558011</td>\n",
       "      <td>0.009129</td>\n",
       "      <td>0.007223</td>\n",
       "      <td>85</td>\n",
       "      <td>28</td>\n",
       "      <td>0.752212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    label  \\\n",
       "interpreta*                                              {interpretación}   \n",
       "trama                                                             {guión}   \n",
       "banda sonora                                          {aspectos formales}   \n",
       "fotografía                                            {aspectos formales}   \n",
       "reparto                                                  {interpretación}   \n",
       "(guion AND NOT actor*)                                            {guión}   \n",
       "director*                                                     {dirección}   \n",
       "total                   {guión, interpretación, aspectos formales, dir...   \n",
       "\n",
       "                        coverage  annotated_coverage  overlaps  conflicts  \\\n",
       "interpreta*             0.028269            0.127072  0.004102   0.003279   \n",
       "trama                   0.012322            0.116022  0.001603   0.001069   \n",
       "banda sonora            0.006168            0.027624  0.001517   0.000968   \n",
       "fotografía              0.008754            0.033149  0.002557   0.002008   \n",
       "reparto                 0.007280            0.038674  0.001647   0.000823   \n",
       "(guion AND NOT actor*)  0.020324            0.110497  0.003351   0.002817   \n",
       "director*               0.039074            0.171271  0.004117   0.004117   \n",
       "total                   0.112427            0.558011  0.009129   0.007223   \n",
       "\n",
       "                        correct  incorrect  precision  \n",
       "interpreta*                  18          5   0.782609  \n",
       "trama                        19          2   0.904762  \n",
       "banda sonora                  4          1   0.800000  \n",
       "fotografía                    4          2   0.666667  \n",
       "reparto                       7          0   1.000000  \n",
       "(guion AND NOT actor*)       12          8   0.600000  \n",
       "director*                    21         10   0.677419  \n",
       "total                        85         28   0.752212  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rubrix.labeling.text_classification import load_rules, WeakLabels\n",
    "\n",
    "weak_labels = WeakLabels(dataset=\"muchocine_aspect_rules\")\n",
    "weak_labels.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6fe30c-1455-45c4-a127-7a079c16f924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rubrix.labeling.text_classification import Snorkel\n",
    "\n",
    "# create the label model\n",
    "label_model = Snorkel(weak_labels)\n",
    "\n",
    "# fit the model\n",
    "label_model.fit()\n",
    "\n",
    "# test it with labeled test set\n",
    "label_model.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ce278425-3362-47a7-a4e3-11a48422c2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get your training records with the predictions of the label model\n",
    "records_for_training = label_model.predict()\n",
    "\n",
    "# optional: log the records to a new dataset in Rubrix\n",
    "#rb.log(records_for_training, name=\"snorkel_results\")\n",
    "\n",
    "# extract training data\n",
    "training_data = pd.DataFrame(\n",
    "    [\n",
    "        {\"text\": rec.text, \"annotation\": rec.prediction[0][0]}\n",
    "        for rec in records_for_training\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8dbf0a00-b578-4e78-9b89-98bfc6634deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La trama de El nombre de la rosa es muy sencilla: en vísperas de que en una abadía benedictina se celebre una cumbre teológica algunos monjes aparecen siniestramente asesinados.</td>\n",
       "      <td>guión</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Las interacciones con el juez (el inolvidable Spencer Tracy), y las de éste con el personaje interpretado por Marlene Dietrich, conforman un producto de enorme calidad y cuyo extenso metraje, que llega a las tres horas, se pasa en un suspiro.</td>\n",
       "      <td>interpretación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Por otra parte, la factura técnica está cuidada, tanto en maquillaje y FX como en fotografía, sonido y música, pero tan sólo brillan de veras esas ovejas amenazadoras.</td>\n",
       "      <td>aspectos formales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mientras, el tío, interpretado brillantemente por Steve Carell, ha dado el paso contrario, ha pasado de ser un triunfador a ser un perdedor.</td>\n",
       "      <td>interpretación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El mejor ejemplo para resumir la frialdad de la película es el gran villano de la película, un tipo llamado Arcángel de Jesús Montoya, papel que interpreta (es un decir) Luis Tosar, recuperando el 'toque español' de 'Collateral'.</td>\n",
       "      <td>interpretación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7677</th>\n",
       "      <td>En esta los rostros de los personajes, los ojos, transmiten emociones y a pesar de su diseño caricaturesco pueden llegar a parececernos seres reales, algo que nunca sucedía con la película interpretada por Tom Hanks.</td>\n",
       "      <td>interpretación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7678</th>\n",
       "      <td>Aunque la secundaria Laura Linney tampoco ha de desmerecerse, pues su interpretación es, como de costumbre, excelente.</td>\n",
       "      <td>interpretación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7679</th>\n",
       "      <td>Otros puntos altos son en primer término, la excelente fotografía de William C. Mellor, en un intenso blanco y negro y bello juego de contrastes, visible hasta en las fotos que acompañan el texto.</td>\n",
       "      <td>aspectos formales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7680</th>\n",
       "      <td>Los sustos baratos tampoco ayudan mucho, a decir verdad, y el giro final que coge la trama se ve venir a leguas.</td>\n",
       "      <td>guión</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7681</th>\n",
       "      <td>Siempre creo que nuestro país es el de los ciegos en materia cinematográfica, no me termino de explicar el porque el director británico SHANE MEADOWS reconocido en medio mundo por su enorme talento, pues aquí ni se estrenan sus filmes.</td>\n",
       "      <td>dirección</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7682 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                    text  \\\n",
       "0                                                                      La trama de El nombre de la rosa es muy sencilla: en vísperas de que en una abadía benedictina se celebre una cumbre teológica algunos monjes aparecen siniestramente asesinados.   \n",
       "1     Las interacciones con el juez (el inolvidable Spencer Tracy), y las de éste con el personaje interpretado por Marlene Dietrich, conforman un producto de enorme calidad y cuyo extenso metraje, que llega a las tres horas, se pasa en un suspiro.   \n",
       "2                                                                                Por otra parte, la factura técnica está cuidada, tanto en maquillaje y FX como en fotografía, sonido y música, pero tan sólo brillan de veras esas ovejas amenazadoras.   \n",
       "3                                                                                                           Mientras, el tío, interpretado brillantemente por Steve Carell, ha dado el paso contrario, ha pasado de ser un triunfador a ser un perdedor.   \n",
       "4                  El mejor ejemplo para resumir la frialdad de la película es el gran villano de la película, un tipo llamado Arcángel de Jesús Montoya, papel que interpreta (es un decir) Luis Tosar, recuperando el 'toque español' de 'Collateral'.   \n",
       "...                                                                                                                                                                                                                                                  ...   \n",
       "7677                            En esta los rostros de los personajes, los ojos, transmiten emociones y a pesar de su diseño caricaturesco pueden llegar a parececernos seres reales, algo que nunca sucedía con la película interpretada por Tom Hanks.   \n",
       "7678                                                                                                                              Aunque la secundaria Laura Linney tampoco ha de desmerecerse, pues su interpretación es, como de costumbre, excelente.   \n",
       "7679                                                Otros puntos altos son en primer término, la excelente fotografía de William C. Mellor, en un intenso blanco y negro y bello juego de contrastes, visible hasta en las fotos que acompañan el texto.   \n",
       "7680                                                                                                                                    Los sustos baratos tampoco ayudan mucho, a decir verdad, y el giro final que coge la trama se ve venir a leguas.   \n",
       "7681         Siempre creo que nuestro país es el de los ciegos en materia cinematográfica, no me termino de explicar el porque el director británico SHANE MEADOWS reconocido en medio mundo por su enorme talento, pues aquí ni se estrenan sus filmes.   \n",
       "\n",
       "             annotation  \n",
       "0                 guión  \n",
       "1        interpretación  \n",
       "2     aspectos formales  \n",
       "3        interpretación  \n",
       "4        interpretación  \n",
       "...                 ...  \n",
       "7677     interpretación  \n",
       "7678     interpretación  \n",
       "7679  aspectos formales  \n",
       "7680              guión  \n",
       "7681          dirección  \n",
       "\n",
       "[7682 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# quick look at our training data with the weak labels from our label model\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc6851-3236-4979-8106-8ebabc73de10",
   "metadata": {},
   "source": [
    "### Push to hub para usarlo como dataset de entrenamiento (usando Colab, AutoNLP, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2358a8e5-666b-4302-9a51-38872db16515",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb.DatasetForTextClassification.from_pandas(\n",
    "    training_data\n",
    ").prepare_for_training(\n",
    ").push_to_hub(\"rubrix/muchocine_aspectos\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d566d248-90f4-453f-94e6-8a803e0feea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb.load(\n",
    "    \"muchocine_aspect_rules\", \n",
    "    query=\"status:Validated\", \n",
    "    as_pandas=False\n",
    ").prepare_for_training(\n",
    ").push_to_hub(\"rubrix/muchocine_aspectos\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00d17ff-bbb0-4f14-9718-887f182e0be8",
   "metadata": {},
   "source": [
    "### Entrenar un baseline en scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6b7f1157-bda6-49c0-b8c1-72836f3aa205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the test set, we can retrieve the records with validated annotations \n",
    "df_test = rb.load(\"muchocine_aspect_rules\", query=\"status:Validated\")\n",
    "\n",
    "# transform data to match our training set format\n",
    "df_test['annotation'] = df_test['annotation'].apply(\n",
    "    lambda r: label_model.weak_labels.label2int[r]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8d57e1c7-d1bd-4944-aba0-858019b37487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# define our final classifier\n",
    "classifier = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "# fit the classifier\n",
    "classifier.fit(\n",
    "    X=training_data.text.tolist(),\n",
    "    y=training_data.annotation.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "61c70bc4-18f3-4563-a85d-60babfb7b45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aspectos formales'], dtype='<U17')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict([\"Buena música\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8aeedc-6a89-48df-982e-9fb5ee4b299f",
   "metadata": {},
   "source": [
    "### Ejercicio: Usar Weasel para entrenar un transformers final directamente con reglas\n",
    "\n",
    "Ver https://rubrix.readthedocs.io/en/master/guides/weak-supervision.html#Joint-Model-with-Weasel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cbcdc3-43c6-48f1-b162-11f9748d4634",
   "metadata": {},
   "source": [
    "## **6. Cómo subir o crear datasets para anotar para NER**\n",
    "\n",
    "### Usando objetos TokenClassification\n",
    "\n",
    "**IMPORTANTE**: El texto pasado como `text` tiene que enviarse tokenizado en el parámetro `tokens`. Para ello es recomendable usar `spaCy` o `tokenizers` e idealmente el mismo tokenizador que se va a usar en tiempo de inferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6cb57f36-c160-4319-b077-c2c4fddafceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750bb80389be489faef1bd1ec02d30d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 records logged to http://localhost:6900/ws/rubrix/ejemplo_ner\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BulkResponse(dataset='ejemplo_ner', processed=1, failed=0)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record = rb.TokenClassificationRecord(\n",
    "    text=\"Mi nombre es Daniel Vila\",\n",
    "    tokens=\"Mi nombre es Daniel Vila\".split() # esto es un MAL tokenizador\n",
    ")\n",
    "rb.log(record, \"ejemplo_ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a88a88-88bf-47a7-9e44-076226a5535c",
   "metadata": {},
   "source": [
    "### Usando from_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cf8c46e3-5240-4a04-8e1f-9773a3e1efe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Se imaginan a los chicos agradeciendo por el p...</td>\n",
       "      <td>tweets_pos_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Eclesiastes4:9-12 ♡ Siempre, promesa :)  https...</td>\n",
       "      <td>tweets_pos_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@pedroj_ramirez Qué saborío, PJ. ya no compart...</td>\n",
       "      <td>tweets_pos_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Buenos dias para todos. Feliz inicio de semana...</td>\n",
       "      <td>tweets_pos_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@pepedom @bquintero Gracias! No es así, deja c...</td>\n",
       "      <td>tweets_pos_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248305</th>\n",
       "      <td>70729</td>\n",
       "      <td>.@EsperanzAguirre y @mdcospedal se presentan a...</td>\n",
       "      <td>tweets_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248306</th>\n",
       "      <td>70730</td>\n",
       "      <td>Desde aquí twiteo siempre http://t.co/JcH0yKr3\\n</td>\n",
       "      <td>tweets_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248307</th>\n",
       "      <td>70731</td>\n",
       "      <td>Es un honor y una necesidad política estar a p...</td>\n",
       "      <td>tweets_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248308</th>\n",
       "      <td>70732</td>\n",
       "      <td>\"La salud y la vida de las mujeres vale más qu...</td>\n",
       "      <td>tweets_clean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248309</th>\n",
       "      <td>70733</td>\n",
       "      <td>Cinco estafadores que todo emprendedor se enco...</td>\n",
       "      <td>tweets_clean.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248310 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  \\\n",
       "0                0  Se imaginan a los chicos agradeciendo por el p...   \n",
       "1                1  Eclesiastes4:9-12 ♡ Siempre, promesa :)  https...   \n",
       "2                2  @pedroj_ramirez Qué saborío, PJ. ya no compart...   \n",
       "3                3  Buenos dias para todos. Feliz inicio de semana...   \n",
       "4                4  @pepedom @bquintero Gracias! No es así, deja c...   \n",
       "...            ...                                                ...   \n",
       "248305       70729  .@EsperanzAguirre y @mdcospedal se presentan a...   \n",
       "248306       70730   Desde aquí twiteo siempre http://t.co/JcH0yKr3\\n   \n",
       "248307       70731  Es un honor y una necesidad política estar a p...   \n",
       "248308       70732  \"La salud y la vida de las mujeres vale más qu...   \n",
       "248309       70733  Cinco estafadores que todo emprendedor se enco...   \n",
       "\n",
       "                      source  \n",
       "0       tweets_pos_clean.txt  \n",
       "1       tweets_pos_clean.txt  \n",
       "2       tweets_pos_clean.txt  \n",
       "3       tweets_pos_clean.txt  \n",
       "4       tweets_pos_clean.txt  \n",
       "...                      ...  \n",
       "248305      tweets_clean.txt  \n",
       "248306      tweets_clean.txt  \n",
       "248307      tweets_clean.txt  \n",
       "248308      tweets_clean.txt  \n",
       "248309      tweets_clean.txt  \n",
       "\n",
       "[248310 rows x 3 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# usando pandas para leer un csv, json, etc.\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/recognai/pln_con_rubrix/main/datos/tweets_en_es.csv\"); df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2e85e549-abb1-429e-bebe-0b2dccf3815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "df = df[0:50]\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "df['tokens'] = df['text'].apply(\n",
    "    lambda r: [t.text for t in nlp(r)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98952876-dc85-4512-abcd-dbcd571a32d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb.log(rb.DatasetForTokenClassification().from_pandas(df), \"pandas_ds_ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c39e5f-32cf-47fc-9760-5ddf3f0c66b6",
   "metadata": {},
   "source": [
    "### Usando el Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0ece62-8d4a-4fb6-a211-2b7282d75cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_ner_dataset = read_datasets(load_dataset(\"rubrix/muchocine_ner\", split=\"unlabelled\"), task=\"TokenClassification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c829cf-c7b9-4681-a4b1-0d12b3b2f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb.log(rb_ner_dataset, \"muchocine_ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb80387-8aa2-44a3-b1e2-77926fd32654",
   "metadata": {},
   "source": [
    "## **7. Cómo etiquetar un dataset para NER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a973820d-3812-4bd2-b466-9ca88253a0cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
